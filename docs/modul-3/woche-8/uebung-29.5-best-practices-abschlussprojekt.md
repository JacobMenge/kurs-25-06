---
tags:
  - Docker
  - Dockerfile
  - Docker-Compose
---
# Best Practices & Abschlussprojekt ‚Äì Praktische √úbungen

## √úbersicht

In dieser √úbung lernst du:

- Wie **Multi-Stage Builds** deine Docker-Images deutlich kleiner machen
- Wie du ein **Multi-Container-Projekt** sauber strukturierst (Ordnerstruktur, Dockerfiles, compose.yaml)
- Wann du Docker **w√§hrend der Entwicklung** einsetzt und wann nicht
- Wie du ein vollst√§ndiges Projekt mit **React + FastAPI + PostgreSQL + MongoDB** containerisierst
- Wie **nginx als Reverse-Proxy** Frontend und Backend verbindet
- Was sich beim **Deployment auf EC2** gegen√ºber deinem Laptop √§ndert
- Welche **Best Practices** professionelle Docker-Projekte auszeichnen

## Inhaltsverzeichnis

| Teil | Thema | Zeitbedarf |
|------|-------|------------|
| **R√ºckblick** | Wiederholung Tag 4 (Docker Compose) | 10 min (lesen) |
| **Teil 1** | Multi-Stage Builds | 20 min |
| **Teil 2** | Projektstruktur planen | 15 min (lesen) |
| **Teil 3** | Wann Docker nutzen? | 10 min (lesen) |
| **Teil 4** | Datenbank-Services aufsetzen | 25 min |
| **Teil 5** | Backend entwickeln | 30 min |
| **Teil 6** | Frontend entwickeln | 25 min |
| **Teil 7** | Alles zusammenf√ºhren | 20 min |
| **Teil 8** | Testen & Debugging | 15 min |
| **Teil 9** | Ausblick: EC2-Deployment | 10 min (lesen) |
| **Bonus** | Best Practices Review | 15 min (optional) |
| | **Gesamt** | **ca. 3‚Äì3,5 Stunden** |

### Minimalpfad (wenn du wenig Zeit hast)

**In 90‚Äì120 Minuten das Abschlussprojekt bauen:**

1. **R√ºckblick** ‚Äì Tag 4 auffrischen (Compose-Grundlagen)
2. **Teil 2** ‚Äì Projektstruktur verstehen
3. **Teil 4** ‚Äì Datenbanken aufsetzen (√úbung 2)
4. **Teil 5** ‚Äì Backend entwickeln (√úbung 3)
5. **Teil 7** ‚Äì Alles zusammenf√ºhren (√úbung 5)
6. **Teil 8** ‚Äì Testen (√úbung 6)

---

## Voraussetzungen & Setup

**Bevor du startest:**

1. Docker Desktop ist installiert und l√§uft
2. Docker Compose ist verf√ºgbar (bei Docker Desktop bereits enthalten)
3. Ein Terminal ist ge√∂ffnet (Git Bash empfohlen unter Windows)
4. Die √úbungen von Tag 1‚Äì4 wurden durchgearbeitet (insbesondere Tag 4: Docker Compose)

**√úberpr√ºfe deine Installation:**

```bash
docker --version
docker compose version
```

> Du solltest die Docker-Version und die Compose-Version sehen. Falls `docker compose version` einen Fehler zeigt, aktualisiere Docker Desktop auf die neueste Version. (‚Üí siehe √úbung 29.4, Voraussetzungen)

---

## R√ºckblick: Wiederholung Tag 4 ‚Äì Docker Compose

Gestern hast du gelernt, mehrere Container mit einer einzigen Datei zu steuern. Bevor wir heute ein ganzes Projekt bauen, frischen wir die wichtigsten Konzepte auf.

```mermaid
%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#e3f2fd', 'primaryTextColor': '#0d47a1', 'primaryBorderColor': '#90caf9', 'secondaryColor': '#e8f5e9', 'secondaryTextColor': '#1b5e20', 'secondaryBorderColor': '#a5d6a7', 'tertiaryColor': '#fff3e0', 'tertiaryTextColor': '#e65100', 'tertiaryBorderColor': '#ffcc80', 'lineColor': '#78909c', 'fontSize': '14px'}}}%%
graph TD
  ENV[".env-Datei"] -->|"${‚Ä¶} Interpolation"| COMPOSE["compose.yaml"]
  COMPOSE -->|"services:"| S1["Service 1<br/>(z.B. api)"]
  COMPOSE -->|"services:"| S2["Service 2<br/>(z.B. db)"]
  COMPOSE -->|"volumes:"| VOL[(Named Volume)]
  subgraph "Automatisches Netzwerk"
    S1 -->|"Service-Name<br/>als Hostname"| S2
  end
  VOL -->|"mount"| S2
  BR["üåê Browser"] -->|"ports: ..."| S1
```

**Was du gestern gelernt hast:**
- **compose.yaml** definiert alle Services, Volumes und Netzwerke in einer Datei
- **`docker compose up -d`** startet alles ‚Äî Netzwerk wird automatisch erstellt
- **Service-Namen** funktionieren als Hostnamen (Docker-DNS)
- **`.env`-Dateien** halten Secrets aus der compose.yaml heraus
- **Healthchecks + `depends_on`** sorgen f√ºr die richtige Startreihenfolge

---

### Wissensfrage 1

**Was erstellt `docker compose up -d` automatisch, das du an Tag 3 noch manuell anlegen musstest?**

<details>
<summary>Antwort anzeigen</summary>

Ein **Bridge-Netzwerk** f√ºr alle Services in der Datei. An Tag 3 musstest du `docker network create mein-netzwerk` manuell ausf√ºhren und bei jedem Container `--network mein-netzwerk` angeben. Compose √ºbernimmt das automatisch ‚Äî alle Services k√∂nnen sich √ºber ihren Service-Namen erreichen. Named Volumes m√ºssen im Top-Level `volumes:` deklariert werden, werden dann aber beim ersten `up` automatisch erstellt. (‚Üí siehe √úbung 29.4, Teil 1 + Teil 5)

</details>

---

### Wissensfrage 2

**Warum sollte eine `.env`-Datei in `.gitignore` stehen, aber eine `.env.example` im Repository?**

<details>
<summary>Antwort anzeigen</summary>

Die **`.env`-Datei** enth√§lt echte Passw√∂rter und Secrets ‚Äî wenn sie in Git landet, sind diese f√ºr jeden sichtbar, der Zugriff auf das Repository hat. Deshalb geh√∂rt `.env` in die `.gitignore`.

Die **`.env.example`** zeigt, welche Variablen ben√∂tigt werden (mit Platzhaltern wie `CHANGE_ME`), und dient als Dokumentation f√ºr Teammitglieder. Sie wird eingecheckt, damit jeder wei√ü, welche Variablen er in seiner eigenen `.env` setzen muss. (‚Üí siehe √úbung 29.4, Teil 6)

</details>

---

### Wissensfrage 3

**Was ist der Unterschied zwischen `depends_on: [db]` (einfach) und `depends_on: db: condition: service_healthy`?**

<details>
<summary>Antwort anzeigen</summary>

- **Einfach (`depends_on: [db]`):** Wartet nur darauf, dass der Container **gestartet** wurde ‚Äî nicht darauf, dass die Anwendung darin bereit ist.
- **Mit Condition (`condition: service_healthy`):** Wartet darauf, dass der **Healthcheck** des abh√§ngigen Services erfolgreich ist ‚Äî die Datenbank also wirklich Verbindungen annimmt.

In der Praxis ist die zweite Variante fast immer besser, weil eine Datenbank einige Sekunden braucht, bis sie bereit ist. Ohne Healthcheck startet deine App, bevor die DB Verbindungen annimmt ‚Üí `Connection refused`. (‚Üí siehe √úbung 29.4, Teil 3)

> **Hinweis:** `condition: service_healthy` gilt f√ºr `docker compose` (Compose CLI). In anderen Orchestratoren (z.B. Docker Swarm) wird das nicht identisch unterst√ºtzt.

</details>

---

## Teil 1: Multi-Stage Builds

### Warum sind Docker-Images oft zu gro√ü?

Wenn du ein Docker-Image baust, enth√§lt es alles, was w√§hrend des Builds ben√∂tigt wurde ‚Äî auch Dinge, die zur Laufzeit nicht mehr gebraucht werden:

| Was wird gebraucht? | Beim Build | Zur Laufzeit |
|---|---|---|
| Python-Interpreter | ‚úÖ | ‚úÖ |
| pip (Package-Manager) | ‚úÖ | ‚ùå |
| gcc/Compiler | ‚úÖ (f√ºr manche Packages) | ‚ùå |
| Header-Dateien | ‚úÖ (f√ºr Kompilierung) | ‚ùå |
| Installierte Packages | ‚úÖ | ‚úÖ |
| Dein Code | ‚úÖ | ‚úÖ |

**Das Problem:** `python:3.11` (das volle Image) enth√§lt Compiler, Build-Tools und Header-Dateien ‚Äî alles zusammen √ºber **1 GB**. Dein Code und die installierten Packages sind vielleicht nur 50 MB.

### Die L√∂sung: Multi-Stage Builds

Ein Multi-Stage Build verwendet **mehrere `FROM`-Anweisungen** in einem Dockerfile. Jede `FROM`-Anweisung startet eine neue "Stage". Du kannst Dateien von einer fr√ºheren Stage in eine sp√§tere kopieren ‚Äî und alles andere wird verworfen.

**Das Prinzip:**

```
Stage 1 (builder):     Gro√ües Image ‚Üí installiere alles ‚Üí baue alles
                            ‚Üì COPY --from=builder
Stage 2 (production):  Kleines Image ‚Üí nur das Ergebnis ‚Üí fertig!
```

---

### √úbung 1: Multi-Stage Python-Image

> **Ziel:** Ein Python-Image mit und ohne Multi-Stage Build erstellen und den Gr√∂√üenunterschied sehen.
>
> **Zeitbedarf:** ca. 15 Minuten
>
> **Du bist fertig, wenn:** `docker image ls` zeigt, dass dein Multi-Stage-Image deutlich kleiner ist als das Standard-Image.

**Schritt 1: Projektordner erstellen**

```bash
mkdir multistage-test && cd multistage-test
```

**Schritt 2: Einfache App erstellen**

Erstelle `app.py`:

```python
from fastapi import FastAPI

app = FastAPI()

@app.get("/")
def hallo():
    return {"message": "Hello Multi-Stage!"}
```

Erstelle `requirements.txt`:

```
fastapi~=0.133.0
uvicorn~=0.41.0
```

**Schritt 3: Dockerfile OHNE Multi-Stage**

Erstelle `Dockerfile`:

```dockerfile
FROM python:3.11
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY app.py .
EXPOSE 8000
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
```

```bash
docker build -t api-gross .
```

**Schritt 4: Dockerfile MIT Multi-Stage**

Ersetze den Inhalt von `Dockerfile` durch:

```dockerfile
# Stage 1: Dependencies in virtuellem Environment installieren
FROM python:3.11 AS builder
WORKDIR /build
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Stage 2: Schlankes Production-Image (ohne pip, gcc, Build-Tools)
FROM python:3.11-slim
WORKDIR /app
COPY --from=builder /opt/venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"
COPY app.py .
EXPOSE 8000
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
```

> **Was passiert hier?**
> - **Stage 1 (`builder`):** Nutzt das volle `python:3.11` Image und installiert alle Packages in einem isolierten **virtuellen Environment** (`/opt/venv`).
> - **Stage 2:** Nutzt das schlanke `python:3.11-slim` Image und kopiert **nur das fertige venv** aus Stage 1 ‚Äî kein pip, kein Build-Cache, keine Build-Tools.
> - **Hauptgewinn:** Der Wechsel von `python:3.11` (~1 GB, mit gcc/Build-Tools) auf `python:3.11-slim` (~150 MB). Durch das venv-Copy wird sauber nur das N√∂tige √ºbertragen. Bei Packages, die C-Kompilierung brauchen (z.B. `psycopg2` ohne `-binary`), w√§re Multi-Stage sogar zwingend n√∂tig ‚Äî Build mit gcc in Stage 1, Runtime ohne.

```bash
docker build -t api-klein .
```

**Schritt 5: Gr√∂√üenvergleich**

```bash
docker image ls --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}" | grep api
```

<details>
<summary>PowerShell</summary>

```powershell
docker image ls --format "table {{.Repository}}`t{{.Tag}}`t{{.Size}}" | Select-String api
```

</details>

<details>
<summary>CMD</summary>

```cmd
docker image ls --format "table {{.Repository}}	{{.Tag}}	{{.Size}}" | findstr api
```

</details>

Du solltest ungef√§hr sehen:

```
api-gross    latest    ~1.05 GB
api-klein    latest    ~200 MB
```

> **~5x kleiner!** Weniger Speicher, schnelleres Deployment, weniger Angriffsfl√§che.

**Schritt 6: Testen (optional)**

```bash
docker run --rm -d -p 8000:8000 --name test-multi api-klein
```

> **Port-Hinweis:** Falls Port 8000 belegt ist, verwende `-p 8001:8000` und √∂ffne `http://localhost:8001`.

Browser: `http://localhost:8000` ‚Üí `{"message": "Hello Multi-Stage!"}`

```bash
docker stop test-multi
```

**Aufr√§umen:**

```bash
docker image rm api-gross api-klein
```

<details>
<summary>Git Bash / macOS / Linux</summary>

```bash
cd ..
rm -rf multistage-test
```

</details>

<details>
<summary>PowerShell</summary>

```powershell
cd ..
Remove-Item -Recurse -Force multistage-test
```

</details>

<details>
<summary>CMD</summary>

```cmd
cd ..
rmdir /s /q multistage-test
```

</details>

> **Vorschau:** In Teil 6 nutzen wir Multi-Stage f√ºr das React-Frontend ‚Äî dort ist der Unterschied noch dramatischer: Ein Node.js-Build-Image (~1 GB) wird zu einem nginx-Image (~40 MB), das nur die fertigen HTML/JS-Dateien enth√§lt.

---

### Wissensfrage 4

**Was ist der Hauptvorteil eines Multi-Stage Builds? Nenne ein konkretes Beispiel.**

<details>
<summary>Antwort anzeigen</summary>

**Kleinere Images** ‚Äî weniger Speicherverbrauch, schnelleres Deployment, weniger Angriffsfl√§che (keine unn√∂tigen Tools im Production-Image).

**Beispiel React-Frontend:** Stage 1 nutzt `node:20` (~1 GB) f√ºr `npm install` und `npm run build`. Stage 2 nutzt `nginx:alpine` (~40 MB) und kopiert nur den `dist/`-Ordner (die fertigen HTML/CSS/JS-Dateien). Das finale Image ist ~50 MB statt ~1 GB.

**Beispiel Python-Backend:** Stage 1 nutzt `python:3.11` (mit Compiler, ~1 GB) f√ºr `pip install`. Stage 2 nutzt `python:3.11-slim` (~150 MB) und kopiert nur die installierten Packages.

</details>

---

## Teil 2: Projektstruktur planen

Bevor wir Code schreiben, planen wir die Ordnerstruktur. Bei Multi-Container-Projekten ist eine klare Organisation entscheidend.

### Das Abschlussprojekt: Rezeptbuch

Wir bauen ein **Rezeptbuch** ‚Äî eine Web-App zum Sammeln und Anzeigen von Rezepten:

| Komponente | Technologie | Container | Warum? |
|---|---|---|---|
| **Frontend** | React (Vite) | nginx:alpine | UI im Browser |
| **Backend** | FastAPI (Python) | python:3.11-slim | REST-API |
| **SQL-Datenbank** | PostgreSQL | postgres:16 | Kategorien (strukturiert) |
| **NoSQL-Datenbank** | MongoDB | mongo:7 | Rezepte (flexibles Schema) |

> **Warum zwei Datenbanken?** Das ist "Polyglot Persistence" (‚Üí siehe Lektion 28.3): Verschiedene Datentypen in der jeweils passenden Datenbank speichern. Kategorien sind strukturiert und relational ‚Üí SQL. Rezepte haben flexible Felder (verschiedene Rezepte brauchen unterschiedliche Informationen) ‚Üí NoSQL/Dokumente.

### Die Ordnerstruktur

```
rezeptbuch/
‚îú‚îÄ‚îÄ compose.yaml            ‚Üê Steuert alles (im Projekt-Root)
‚îú‚îÄ‚îÄ .env                    ‚Üê Echte Secrets (in .gitignore!)
‚îú‚îÄ‚îÄ .env.example            ‚Üê Vorlage f√ºr Teammitglieder (in Git)
‚îú‚îÄ‚îÄ .gitignore              ‚Üê .env, node_modules, __pycache__
‚îÇ
‚îú‚îÄ‚îÄ backend/                ‚Üê Eigener Ordner pro Service
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile          ‚Üê Eigenes Dockerfile pro Service
‚îÇ   ‚îú‚îÄ‚îÄ .dockerignore       ‚Üê Dateien vom Build ausschlie√üen
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ app.py
‚îÇ
‚îî‚îÄ‚îÄ frontend/               ‚Üê Eigener Ordner pro Service
    ‚îú‚îÄ‚îÄ Dockerfile          ‚Üê Eigenes Dockerfile pro Service
    ‚îú‚îÄ‚îÄ .dockerignore
    ‚îú‚îÄ‚îÄ nginx.conf          ‚Üê nginx-Konfiguration
    ‚îú‚îÄ‚îÄ package.json
    ‚îú‚îÄ‚îÄ index.html
    ‚îú‚îÄ‚îÄ vite.config.js
    ‚îî‚îÄ‚îÄ src/
        ‚îú‚îÄ‚îÄ main.jsx
        ‚îî‚îÄ‚îÄ App.jsx
```

**Wichtige Regeln:**

1. **`compose.yaml` im Projekt-Root** ‚Äî sie steuert alle Services und wird als erstes gelesen
2. **Jeder eigene Service** (Backend, Frontend) hat einen **eigenen Ordner mit eigenem Dockerfile**
3. **Fertige Images** (PostgreSQL, MongoDB) brauchen **kein Dockerfile** ‚Äî sie werden direkt aus Docker Hub gezogen
4. **`.env` neben der compose.yaml** ‚Äî Compose l√§dt sie automatisch

```mermaid
%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#e3f2fd', 'primaryTextColor': '#0d47a1', 'primaryBorderColor': '#90caf9', 'secondaryColor': '#e8f5e9', 'secondaryTextColor': '#1b5e20', 'secondaryBorderColor': '#a5d6a7', 'tertiaryColor': '#fff3e0', 'tertiaryTextColor': '#e65100', 'tertiaryBorderColor': '#ffcc80', 'lineColor': '#78909c', 'fontSize': '14px'}}}%%
graph TD
  ROOT["üìÑ compose.yaml<br/>(Projekt-Root)"]
  ROOT -->|"build: ./backend"| BE["üìÅ backend/<br/>Dockerfile + app.py"]
  ROOT -->|"build: ./frontend"| FE["üìÅ frontend/<br/>Dockerfile + App.jsx"]
  ROOT -->|"image: postgres:16"| PG["üêò PostgreSQL<br/>(kein Dockerfile n√∂tig)"]
  ROOT -->|"image: mongo:7"| MO["üçÉ MongoDB<br/>(kein Dockerfile n√∂tig)"]
```

> **Merke:** `build: ./backend` sagt Compose: "Baue das Image aus dem Dockerfile im Ordner `backend/`". `image: postgres:16` sagt: "Ziehe das fertige Image von Docker Hub." (‚Üí siehe √úbung 29.4, Teil 3: `image:` vs `build:`)

---

### Wissensfrage 5

**Warum hat jeder Service (Backend, Frontend) seinen eigenen Ordner mit eigenem Dockerfile, statt alles in ein Dockerfile zu packen?**

<details>
<summary>Antwort anzeigen</summary>

**Separation of Concerns:** Jeder Service hat andere Technologien und Build-Schritte ‚Äî das Backend braucht Python und pip, das Frontend braucht Node.js und npm. Ein gemeinsames Dockerfile w√§re riesig und schwer wartbar.

**Eigener Build-Context:** Jeder Ordner ist ein eigener Build-Context ‚Üí Docker sendet nur die relevanten Dateien an den Build-Daemon. Das macht Builds schneller und Images kleiner.

**Unabh√§ngige Entwicklung:** Backend und Frontend k√∂nnen von verschiedenen Personen gleichzeitig entwickelt, gebaut und getestet werden.

</details>

---

## Teil 3: Wann Docker nutzen?

Eine h√§ufige Frage: "Soll ich von Anfang an alles in Docker entwickeln?" Die Antwort: **Nein ‚Äî aber Datenbanken sofort.**

### Der empfohlene Development-Workflow

```mermaid
%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#e3f2fd', 'primaryTextColor': '#0d47a1', 'primaryBorderColor': '#90caf9', 'secondaryColor': '#e8f5e9', 'secondaryTextColor': '#1b5e20', 'secondaryBorderColor': '#a5d6a7', 'tertiaryColor': '#fff3e0', 'tertiaryTextColor': '#e65100', 'tertiaryBorderColor': '#ffcc80', 'lineColor': '#78909c', 'fontSize': '14px'}}}%%
graph LR
  A["1Ô∏è‚É£ Docker-DBs<br/>starten"] --> B["2Ô∏è‚É£ Code lokal<br/>schreiben"]
  B --> C["3Ô∏è‚É£ Lokal testen<br/>(gegen Docker-DBs)"]
  C --> D["4Ô∏è‚É£ Dockerfiles<br/>schreiben"]
  D --> E["5Ô∏è‚É£ compose.yaml<br/>erstellen"]
  E --> F["6Ô∏è‚É£ Alles testen<br/>(docker compose up)"]
  F --> G["7Ô∏è‚É£ Deploy<br/>(EC2)"]
```

| Phase | Was tun? | Warum? |
|-------|----------|--------|
| **1. Datenbanken** | `docker compose up -d` (nur DB-Services) | Kein lokales PostgreSQL/MongoDB installieren! Docker macht es einfach. |
| **2. Code schreiben** | Backend/Frontend in deiner IDE | Hot-Reload, Debugging, schnelle Iteration |
| **3. Lokal testen** | `uvicorn app:app --reload` / `npm run dev` | Direkte Ausf√ºhrung ist schneller als Docker-Rebuild |
| **4. Dockerfiles** | Erstellen, wenn der Code funktioniert | Erst containerisieren, wenn klar ist, was gebraucht wird |
| **5. compose.yaml** | Alle Services zusammen definieren | Ein Befehl startet alles ‚Äî reproduzierbar |
| **6. Alles testen** | `docker compose up -d --build` | End-to-End-Test im containerisierten Setup |
| **7. Deployment** | Gleiche compose.yaml auf EC2 | Was lokal l√§uft, l√§uft auch auf dem Server |

> **Faustregel:** Docker f√ºr Datenbanken ab Tag 1. Code containerisieren erst, wenn er l√§uft.

> **Warum nicht sofort alles im Container?** Lokale Entwicklung bietet Hot-Reload (Code-√Ñnderungen sofort sichtbar), bessere IDE-Integration (Debugging, Autocomplete), und schnellere Iteration (kein Image-Rebuild n√∂tig).

**In dieser √úbung** erstellen wir alle Dateien und bauen dann alles zusammen mit Docker Compose. In einem echten Projekt w√ºrdest du Schritte 2‚Äì3 vor 4‚Äì5 machen.

---

## Teil 4: Datenbank-Services aufsetzen

Wir starten mit den Datenbanken ‚Äî genau wie im empfohlenen Workflow.

### √úbung 2: PostgreSQL + MongoDB in compose.yaml

> **Ziel:** Beide Datenbanken per Compose starten und testen, dass sie laufen.
>
> **Zeitbedarf:** ca. 20 Minuten
>
> **Du bist fertig, wenn:** Beide Datenbanken laufen, Healthchecks gr√ºn sind, und du per `docker compose exec` SQL- bzw. MongoDB-Befehle ausf√ºhren kannst.

**Schritt 1: Projektordner erstellen**

```bash
mkdir rezeptbuch && cd rezeptbuch
```

**Schritt 2: `.env`-Datei erstellen**

Erstelle `.env`:

```
POSTGRES_USER=admin
POSTGRES_PASSWORD=geheim123
POSTGRES_DB=rezepte
MONGO_USER=admin
MONGO_PASSWORD=geheim123
```

> **Erinnerung:** `.env` = Werte f√ºr `${‚Ä¶}`-Ersetzung in der compose.yaml (Compose-Interpreter). In den Container kommen Variablen nur, wenn du sie unter `environment:` oder `env_file:` explizit setzt. Bei Konflikten gilt eine [feste Reihenfolge (Precedence)](https://docs.docker.com/compose/how-tos/environment-variables/envvars-precedence/). (‚Üí siehe √úbung 29.4, Teil 6)

Erstelle `.env.example`:

```
POSTGRES_USER=admin
POSTGRES_PASSWORD=CHANGE_ME
POSTGRES_DB=rezepte
MONGO_USER=admin
MONGO_PASSWORD=CHANGE_ME
```

**Schritt 3: `compose.yaml` erstellen**

Erstelle `compose.yaml`:

> **Erinnerung:** Standard-Dateiname ist `compose.yaml` (empfohlen) oder `compose.yml`. Der √§ltere Name `docker-compose.yml` funktioniert weiterhin (Backward Compatibility). Und denke daran: **2 Spaces, keine Tabs!** (‚Üí siehe √úbung 29.4, Teil 2)

```yaml
services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - pg-daten:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 5s
      timeout: 5s
      retries: 5

  mongo:
    image: mongo:7
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
    volumes:
      - mongo-daten:/data/db
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "mongosh --quiet -u $$MONGO_INITDB_ROOT_USERNAME -p $$MONGO_INITDB_ROOT_PASSWORD --authenticationDatabase admin --eval \"db.adminCommand('ping').ok\" | grep 1",
        ]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 20s

volumes:
  pg-daten:
  mongo-daten:
```

> **Warum `$$`?** In Compose-Dateien ersetzt `${VAR}` eine Variable aus der `.env`-Datei (Compose-Interpolation). Wenn du stattdessen die **Container-Umgebungsvariable** ansprechen willst (die zur Laufzeit im Container existiert), musst du `$$` schreiben ‚Äî Compose gibt dann ein einfaches `$` an die Shell weiter.

> **Hinweis:** Die `POSTGRES_*`-Umgebungsvariablen werden nur beim **ersten Start** ausgewertet (wenn das Data-Directory noch leer ist). Wenn du Benutzername oder Passwort √§ndern willst, musst du das Volume l√∂schen: `docker compose down -v`. (‚Üí siehe √úbung 29.4, Teil 3)

> **Sicherheitstipp:** Wenn du die Datenbank-Ports zum Testen exponierst (z.B. `ports: - "5432:5432"`), verwende `"127.0.0.1:5432:5432"` ‚Äî damit ist der Port nur lokal erreichbar, nicht im LAN. F√ºr diese √úbung exponieren wir die DB-Ports **nicht** ‚Äî nur das Backend wird sp√§ter darauf zugreifen.

**Schritt 4: Starten und pr√ºfen**

```bash
docker compose up -d
```

```bash
docker compose ps
```

Beide Services sollten `running` (healthy) zeigen. Falls ein Service noch startet, warte einen Moment und pr√ºfe erneut.

**Schritt 5: PostgreSQL testen**

```bash
docker compose exec postgres psql -U admin -d rezepte -c "SELECT 'PostgreSQL l√§uft!' AS status;"
```

Du solltest sehen:

```
       status
---------------------
 PostgreSQL l√§uft!
```

**Schritt 6: MongoDB testen**

```bash
docker compose exec mongo mongosh -u admin -p geheim123 --authenticationDatabase admin --eval "db.adminCommand('ping')"
```

Du solltest `{ ok: 1 }` sehen.

**Schritt 7: Logs pr√ºfen (bei Problemen)**

```bash
docker compose logs postgres
docker compose logs mongo
```

> **Nicht aufr√§umen!** Wir bauen in den n√§chsten Teilen auf diesem Projekt weiter. Die Datenbanken sollen laufen bleiben.

---

### Wissensfrage 6

**Warum starten wir die Datenbanken zuerst, bevor wir das Backend oder Frontend entwickeln?**

<details>
<summary>Antwort anzeigen</summary>

Weil Backend und Frontend **gegen die Datenbanken entwickelt und getestet werden**. Ohne laufende Datenbank kannst du keine API-Endpoints testen, die Daten lesen oder schreiben.

Docker macht das einfach: `docker compose up -d` startet PostgreSQL und MongoDB in Sekunden ‚Äî ohne lokale Installation, ohne Konfiguration, ohne Versionskonflikte. Das ist einer der gr√∂√üten Vorteile von Docker in der Entwicklung.

</details>

---

## Teil 5: Backend entwickeln

Jetzt erstellen wir die FastAPI-API, die beide Datenbanken nutzt.

### Die API-Endpoints

| Methode | Pfad | Datenbank | Beschreibung |
|---------|------|-----------|-------------|
| GET | `/api/kategorien` | PostgreSQL | Alle Kategorien abrufen |
| POST | `/api/kategorien` | PostgreSQL | Neue Kategorie anlegen |
| GET | `/api/rezepte` | MongoDB | Alle Rezepte abrufen |
| GET | `/api/rezepte?kategorie=1` | MongoDB | Rezepte nach Kategorie filtern |
| POST | `/api/rezepte` | MongoDB | Neues Rezept anlegen |
| GET | `/api/health` | Beide | Status beider Datenbanken pr√ºfen |

> **Beachte:** PostgreSQL-Endpoints nutzen `psycopg2` (synchron, `def`) ‚Äî wie in √úbung 29.3/29.4. MongoDB-Endpoints nutzen `motor` (asynchron, `async def`) ‚Äî wie in Lektion 28.3. FastAPI kann beides in derselben App.

### √úbung 3: FastAPI-Backend erstellen

> **Ziel:** Ein FastAPI-Backend erstellen, das Kategorien in PostgreSQL und Rezepte in MongoDB speichert.
>
> **Zeitbedarf:** ca. 25 Minuten
>
> **Du bist fertig, wenn:** Alle Endpoints funktionieren und du per Browser Kategorien und Rezepte anlegen und abrufen kannst.

**Schritt 1: Backend-Ordner erstellen**

```bash
mkdir backend
```

**Schritt 2: `backend/requirements.txt` erstellen**

```
fastapi~=0.133.0
uvicorn~=0.41.0
psycopg2-binary~=2.9.0
motor~=3.6.0
```

**Schritt 3: `backend/app.py` erstellen**

```python
from fastapi import FastAPI
from pydantic import BaseModel
import os
import psycopg2
from motor.motor_asyncio import AsyncIOMotorClient

app = FastAPI()

# --- Datenbank-Verbindungen ---

DATABASE_URL = os.getenv(
    "DATABASE_URL",
    "postgresql://admin:geheim123@postgres:5432/rezepte"
)
MONGO_URL = os.getenv(
    "MONGO_URL",
    "mongodb://admin:geheim123@mongo:27017/?authSource=admin"
)

mongo_client = AsyncIOMotorClient(MONGO_URL)
mongo_db = mongo_client.rezeptbuch


def get_pg():
    return psycopg2.connect(DATABASE_URL)


@app.on_event("startup")
def startup():
    conn = get_pg()
    cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS kategorien (
            id SERIAL PRIMARY KEY,
            name VARCHAR(100) NOT NULL
        )
    """)
    conn.commit()
    cur.close()
    conn.close()


# --- Kategorien (PostgreSQL) ---

class KategorieInput(BaseModel):
    name: str


@app.get("/api/kategorien")
def get_kategorien():
    conn = get_pg()
    cur = conn.cursor()
    cur.execute("SELECT id, name FROM kategorien ORDER BY id")
    rows = cur.fetchall()
    cur.close()
    conn.close()
    return [{"id": r[0], "name": r[1]} for r in rows]


@app.post("/api/kategorien")
def add_kategorie(kat: KategorieInput):
    conn = get_pg()
    cur = conn.cursor()
    cur.execute(
        "INSERT INTO kategorien (name) VALUES (%s) RETURNING id",
        (kat.name,)
    )
    new_id = cur.fetchone()[0]
    conn.commit()
    cur.close()
    conn.close()
    return {"id": new_id, "name": kat.name}


# --- Rezepte (MongoDB) ---

class RezeptInput(BaseModel):
    titel: str
    kategorie_id: int
    zutaten: list[str]
    schritte: list[str]


@app.get("/api/rezepte")
async def get_rezepte(kategorie: int = None):
    query = {}
    if kategorie is not None:
        query["kategorie_id"] = kategorie

    rezepte = []
    async for doc in mongo_db.rezepte.find(query):
        doc["_id"] = str(doc["_id"])
        rezepte.append(doc)
    return rezepte


@app.post("/api/rezepte")
async def add_rezept(rezept: RezeptInput):
    doc = rezept.model_dump()
    result = await mongo_db.rezepte.insert_one(doc)
    return {"id": str(result.inserted_id), "titel": rezept.titel}


# --- Health ---

@app.get("/api/health")
async def health():
    status = {"postgres": "error", "mongo": "error"}
    try:
        conn = get_pg()
        cur = conn.cursor()
        cur.execute("SELECT 1")
        cur.close()
        conn.close()
        status["postgres"] = "connected"
    except Exception as e:
        status["postgres"] = str(e)
    try:
        await mongo_client.admin.command("ping")
        status["mongo"] = "connected"
    except Exception as e:
        status["mongo"] = str(e)
    return status
```

> **Hinweis:** `@app.on_event("startup")` funktioniert, ist aber zugunsten der [Lifespan-API](https://fastapi.tiangolo.com/advanced/events/#lifespan) als deprecated markiert. F√ºr diese √úbung ist es ausreichend.

> **Beachte den Code:**
> - **PostgreSQL-Endpoints** (`get_kategorien`, `add_kategorie`) sind `def` (synchron) ‚Üí FastAPI f√ºhrt sie in einem Thread-Pool aus. `psycopg2` ist ein synchroner Treiber. (‚Üí siehe √úbung 29.3/29.4)
> - **MongoDB-Endpoints** (`get_rezepte`, `add_rezept`) sind `async def` (asynchron) ‚Üí nutzen `motor`, den asynchronen MongoDB-Treiber. (‚Üí siehe Lektion 28.3)
> - Beide Ans√§tze funktionieren problemlos in derselben FastAPI-App.

> **Hinweis zu psycopg2-binary:** F√ºr √úbungen und Entwicklung ist `psycopg2-binary` ideal ‚Äî es funktioniert ohne System-Dependencies. In echten Produktionsumgebungen nutzt man oft [psycopg (v3)](https://www.psycopg.org/psycopg3/) oder baut `psycopg2` gegen die System-libpq.

**Schritt 4: `backend/Dockerfile` erstellen**

```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY app.py .
EXPOSE 8000
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
```

> **Warum kein Multi-Stage hier?** Unsere Python-Packages (fastapi, motor, psycopg2-binary) sind alle als vorkompilierte Wheels verf√ºgbar und brauchen keinen Compiler. `python:3.11-slim` reicht als Basis. Den echten Multi-Stage-Vorteil siehst du beim React-Frontend in Teil 6. (‚Üí siehe √úbung 29.2 f√ºr Dockerfile-Grundlagen)

**Schritt 5: `backend/.dockerignore` erstellen**

```
__pycache__
*.pyc
.env
```

**Schritt 6: compose.yaml erweitern**

F√ºge den `api`-Service zur bestehenden `compose.yaml` hinzu (unter den bestehenden Services, vor `volumes:`):

```yaml
  api:
    build: ./backend
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
    environment:
      DATABASE_URL: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}"
      MONGO_URL: "mongodb://${MONGO_USER}:${MONGO_PASSWORD}@mongo:27017/?authSource=admin"
```

> **Port-Hinweis:** Falls Port 8000 belegt ist, verwende `"8001:8000"` und √∂ffne `http://localhost:8001`.

> **Beachte:** Die Service-Namen `postgres` und `mongo` aus der compose.yaml werden als Hostnamen in den URLs verwendet ‚Äî genau wie in √úbung 29.3 (Container-Name = Hostname) und √úbung 29.4 (Service-Name = Hostname). (‚Üí siehe √úbung 29.3, Teil 4)

**Schritt 7: Backend starten und testen**

```bash
docker compose up -d --build
```

```bash
docker compose ps
```

Alle drei Services sollten laufen. Pr√ºfe die Logs bei Problemen:

```bash
docker compose logs api
```

**Schritt 8: API testen**

FastAPI erstellt automatisch eine interaktive API-Dokumentation. √ñffne im Browser:

`http://localhost:8000/docs`

Dort kannst du alle Endpoints direkt testen:

1. **Health-Check:** Klicke auf `GET /api/health` ‚Üí "Try it out" ‚Üí "Execute"
   ‚Üí Sollte `{"postgres": "connected", "mongo": "connected"}` zeigen

2. **Kategorie anlegen:** Klicke auf `POST /api/kategorien` ‚Üí "Try it out"
   ‚Üí Gib ein: `{"name": "Hauptgerichte"}` ‚Üí "Execute"

3. **Kategorien abrufen:** `GET /api/kategorien` ‚Üí "Try it out" ‚Üí "Execute"
   ‚Üí Sollte deine Kategorie zeigen

4. **Rezept anlegen:** `POST /api/rezepte` ‚Üí "Try it out"
   ‚Üí Gib ein:
   ```json
   {
     "titel": "Spaghetti Carbonara",
     "kategorie_id": 1,
     "zutaten": ["Spaghetti", "Eier", "Pecorino", "Guanciale", "Pfeffer"],
     "schritte": ["Wasser kochen", "Pasta kochen", "Sauce zubereiten", "Alles vermischen"]
   }
   ```
   ‚Üí "Execute"

5. **Rezepte abrufen:** `GET /api/rezepte` ‚Üí "Try it out" ‚Üí "Execute"
   ‚Üí Sollte dein Rezept zeigen

> **Tipp:** Du kannst die API auch direkt im Browser testen: `http://localhost:8000/api/kategorien` zeigt die Kategorien als JSON.

<details>
<summary>Troubleshooting: API startet nicht oder Connection refused</summary>

1. **Logs pr√ºfen:**
   ```bash
   docker compose logs api
   ```

2. **H√§ufige Fehler:**
   - `ModuleNotFoundError: No module named 'motor'` ‚Üí `requirements.txt` pr√ºfen, dann `docker compose up -d --build`
   - `Connection refused` zur DB ‚Üí Healthchecks pr√ºfen: `docker compose ps`. Laufen alle DBs?
   - `authentication failed` bei MongoDB ‚Üí `.env`-Werte pr√ºfen: `MONGO_USER` und `MONGO_PASSWORD` m√ºssen mit `MONGO_INITDB_ROOT_USERNAME`/`PASSWORD` √ºbereinstimmen

3. **compose.yaml validieren:**
   ```bash
   docker compose config
   ```

4. **Manuell testen (im API-Container):**
   ```bash
   docker compose exec api python -c "import psycopg2; print('psycopg2 OK')"
   docker compose exec api python -c "import motor; print('motor OK')"
   ```

</details>

---

### Wissensfrage 7

**Der Backend-Code verbindet sich zu `postgres:5432` und `mongo:27017`. Warum funktionieren diese Hostnamen, obwohl kein DNS-Server konfiguriert wurde?**

<details>
<summary>Antwort anzeigen</summary>

Docker Compose erstellt automatisch ein **Bridge-Netzwerk** f√ºr alle Services in der compose.yaml. In diesem Netzwerk l√§uft ein **eingebauter DNS-Server**, der Service-Namen auf Container-IP-Adressen aufl√∂st.

`postgres` ‚Üí IP des postgres-Containers, `mongo` ‚Üí IP des mongo-Containers. Kein manuelles `docker network create` n√∂tig ‚Äî Compose √ºbernimmt das automatisch. (‚Üí siehe √úbung 29.3, Teil 4: Docker-Netzwerke + √úbung 29.4, Teil 5: Compose-Netzwerk)

</details>

---

## Teil 6: Frontend entwickeln

Jetzt erstellen wir ein einfaches React-Frontend, das die API nutzt.

### Das Konzept: nginx als Reverse-Proxy

Das Frontend wird als statische Dateien gebaut (HTML, CSS, JavaScript) und von nginx ausgeliefert. Zus√§tzlich konfigurieren wir nginx als **Reverse-Proxy**: Alle Anfragen an `/api/` werden intern an den Backend-Service weitergeleitet.

```
Browser ‚Üí http://localhost:3000/            ‚Üí nginx ‚Üí index.html (React-App)
Browser ‚Üí http://localhost:3000/api/rezepte ‚Üí nginx ‚Üí http://api:8000/api/rezepte
```

> **Warum ein Proxy?** Ohne Proxy m√ºsste der Browser direkt `http://localhost:8000` aufrufen ‚Äî das w√§re ein **anderer Origin** ‚Üí CORS-Probleme. Mit dem Proxy l√§uft alles √ºber **einen Eingang** (Port 3000). In der Produktion gibt es kein `localhost:8000`.

### √úbung 4: React-Frontend erstellen

> **Ziel:** Ein einfaches React-Frontend erstellen, das die API nutzt, und per Multi-Stage Build in einen nginx-Container verpacken.
>
> **Zeitbedarf:** ca. 20 Minuten
>
> **Du bist fertig, wenn:** Das Frontend unter `http://localhost:3000` die Rezepte anzeigt.

**Schritt 1: Frontend-Ordner erstellen**

```bash
mkdir -p frontend/src
```

**Schritt 2: `frontend/package.json` erstellen**

```json
{
  "name": "rezeptbuch",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0"
  },
  "devDependencies": {
    "@vitejs/plugin-react": "^4.2.0",
    "vite": "^5.4.0"
  }
}
```

**Schritt 3: `frontend/vite.config.js` erstellen**

```js
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

export default defineConfig({
  plugins: [react()]
})
```

**Schritt 4: `frontend/index.html` erstellen**

```html
<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Rezeptbuch</title>
</head>
<body>
  <div id="root"></div>
  <script type="module" src="/src/main.jsx"></script>
</body>
</html>
```

**Schritt 5: `frontend/src/main.jsx` erstellen**

```jsx
import React from 'react'
import ReactDOM from 'react-dom/client'
import App from './App'

ReactDOM.createRoot(document.getElementById('root')).render(
  <React.StrictMode>
    <App />
  </React.StrictMode>
)
```

**Schritt 6: `frontend/src/App.jsx` erstellen**

```jsx
import { useState, useEffect } from "react"

function App() {
  const [kategorien, setKategorien] = useState([])
  const [rezepte, setRezepte] = useState([])
  const [neueKategorie, setNeueKategorie] = useState("")
  const [titel, setTitel] = useState("")
  const [kategorieId, setKategorieId] = useState("")
  const [zutaten, setZutaten] = useState("")
  const [schritte, setSchritte] = useState("")

  useEffect(() => {
    laden()
  }, [])

  function laden() {
    fetch("/api/kategorien").then(r => r.json()).then(setKategorien)
    fetch("/api/rezepte").then(r => r.json()).then(setRezepte)
  }

  function kategorieAnlegen(e) {
    e.preventDefault()
    fetch("/api/kategorien", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ name: neueKategorie })
    }).then(() => {
      setNeueKategorie("")
      laden()
    })
  }

  function rezeptAnlegen(e) {
    e.preventDefault()
    fetch("/api/rezepte", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        titel,
        kategorie_id: Number(kategorieId),
        zutaten: zutaten.split("\n").filter(z => z.trim()),
        schritte: schritte.split("\n").filter(s => s.trim())
      })
    }).then(() => {
      setTitel("")
      setKategorieId("")
      setZutaten("")
      setSchritte("")
      laden()
    })
  }

  return (
    <div style={{ maxWidth: 700, margin: "0 auto", padding: 20, fontFamily: "sans-serif" }}>
      <h1>Rezeptbuch</h1>

      <section>
        <h2>Kategorien</h2>
        <form onSubmit={kategorieAnlegen} style={{ marginBottom: 10 }}>
          <input
            value={neueKategorie}
            onChange={e => setNeueKategorie(e.target.value)}
            placeholder="Neue Kategorie..."
            required
          />
          <button type="submit">Hinzufuegen</button>
        </form>
        <ul>
          {kategorien.map(k => <li key={k.id}>{k.name}</li>)}
        </ul>
      </section>

      <section>
        <h2>Neues Rezept</h2>
        <form onSubmit={rezeptAnlegen}>
          <input
            value={titel}
            onChange={e => setTitel(e.target.value)}
            placeholder="Titel"
            required
            style={{ width: "100%", marginBottom: 5 }}
          />
          <br />
          <select
            value={kategorieId}
            onChange={e => setKategorieId(e.target.value)}
            required
            style={{ marginBottom: 5 }}
          >
            <option value="">Kategorie waehlen...</option>
            {kategorien.map(k => (
              <option key={k.id} value={k.id}>{k.name}</option>
            ))}
          </select>
          <br />
          <textarea
            value={zutaten}
            onChange={e => setZutaten(e.target.value)}
            placeholder="Zutaten (eine pro Zeile)"
            rows={3}
            style={{ width: "100%", marginBottom: 5 }}
          />
          <br />
          <textarea
            value={schritte}
            onChange={e => setSchritte(e.target.value)}
            placeholder="Schritte (einer pro Zeile)"
            rows={3}
            style={{ width: "100%", marginBottom: 5 }}
          />
          <br />
          <button type="submit">Rezept speichern</button>
        </form>
      </section>

      <section>
        <h2>Alle Rezepte ({rezepte.length})</h2>
        {rezepte.length === 0 && <p>Noch keine Rezepte vorhanden.</p>}
        {rezepte.map(r => (
          <div key={r._id} style={{
            border: "1px solid #ddd",
            padding: 15,
            marginBottom: 10,
            borderRadius: 5
          }}>
            <h3 style={{ margin: "0 0 10px" }}>{r.titel}</h3>
            <p><strong>Zutaten:</strong></p>
            <ul>{r.zutaten.map((z, i) => <li key={i}>{z}</li>)}</ul>
            <p><strong>Zubereitung:</strong></p>
            <ol>{r.schritte.map((s, i) => <li key={i}>{s}</li>)}</ol>
          </div>
        ))}
      </section>
    </div>
  )
}

export default App
```

> **Hinweis zum Code:** Das Frontend nutzt `fetch("/api/...")` mit **relativen Pfaden** ‚Äî keine absoluten URLs wie `http://localhost:8000`. Das funktioniert, weil nginx alle `/api/`-Anfragen an das Backend weiterleitet (Reverse-Proxy). So gibt es keine CORS-Probleme und der Code funktioniert gleich in Development und Production.

**Schritt 7: `frontend/nginx.conf` erstellen**

```nginx
server {
    listen 80;

    location / {
        root /usr/share/nginx/html;
        index index.html;
        try_files $uri $uri/ /index.html;
    }

    location /api/ {
        proxy_pass http://api:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

> **Was macht diese Konfiguration?**
> - `location /` ‚Üí Liefert die React-App (statische Dateien) aus
> - `try_files ... /index.html` ‚Üí SPA-Routing: Alle Pfade laden die React-App (Client-Side-Routing)
> - `location /api/` ‚Üí **Reverse-Proxy:** Leitet alle API-Anfragen an den Backend-Container weiter
> - `http://api:8000` ‚Üí `api` ist der Service-Name aus der compose.yaml (Docker-DNS)

**Schritt 8: `frontend/Dockerfile` erstellen (Multi-Stage!)**

```dockerfile
# Stage 1: React-App bauen
FROM node:20-alpine AS build
WORKDIR /app
COPY package*.json .
RUN npm install
COPY . .
RUN npm run build

# Stage 2: Fertige Dateien mit nginx ausliefern
FROM nginx:alpine
COPY --from=build /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/conf.d/default.conf
EXPOSE 80
```

> **Best Practice mit Lockfile:** Wenn du ein `package-lock.json` hast (z.B. nach lokalem `npm install`), nutze `RUN npm ci` statt `npm install` ‚Äî das installiert exakt die Versionen aus dem Lockfile und ist reproduzierbarer. F√ºr diese √úbung reicht `npm install`, da wir kein Lockfile haben.

> **DAS ist Multi-Stage in Aktion!**
> - **Stage 1 (`build`):** `node:20-alpine` (~180 MB) installiert npm-Packages und baut die App ‚Üí erzeugt `dist/`-Ordner mit HTML/CSS/JS
> - **Stage 2:** `nginx:alpine` (~40 MB) kopiert **nur den `dist/`-Ordner** ‚Üí kein Node.js, kein npm, keine node_modules im finalen Image!
> - **Ergebnis:** Statt ~300 MB (Node + node_modules + dist) nur ~45 MB (nginx + dist)

**Schritt 9: `frontend/.dockerignore` erstellen**

```
node_modules
dist
.env
```

> **Wichtig:** `node_modules` ausschlie√üen! Sonst werden lokale node_modules (falls vorhanden) in den Build-Context kopiert und √ºberschreiben die im Container installierte Version. Das kann zu Fehlern f√ºhren.

---

### Wissensfrage 8

**Warum konfigurieren wir im nginx einen Reverse-Proxy f√ºr `/api/`, statt das Frontend direkt mit dem Backend kommunizieren zu lassen?**

<details>
<summary>Antwort anzeigen</summary>

**Ohne Proxy:** Der Browser m√ºsste `http://localhost:8000/api/rezepte` aufrufen ‚Äî das ist ein **anderer Origin** als `http://localhost:3000` (das Frontend). Browser blockieren solche Cross-Origin-Anfragen wegen der **Same-Origin-Policy** (CORS).

**Mit Proxy:** Alles l√§uft √ºber **einen Eingang** (Port 3000). F√ºr den Browser kommt alles vom gleichen Origin. nginx leitet `/api/`-Anfragen intern an den Backend-Container weiter ‚Äî davon merkt der Browser nichts.

**Zus√§tzlicher Vorteil:** In der Produktion (z.B. auf EC2) gibt es kein `localhost:8000`. Der Proxy macht die Architektur flexibel ‚Äî das Frontend muss nicht wissen, wo das Backend physisch l√§uft.

</details>

---

## Teil 7: Alles zusammenf√ºhren

Jetzt verbinden wir alle vier Services in einer einzigen compose.yaml.

### √úbung 5: Komplette compose.yaml

> **Ziel:** Alle 4 Services in einer compose.yaml vereinen und das gesamte Projekt starten.
>
> **Zeitbedarf:** ca. 15 Minuten
>
> **Du bist fertig, wenn:** `docker compose up -d --build` alle 4 Services startet und das Frontend unter `http://localhost:3000` die Rezepte anzeigt.

**Schritt 1: Bestehende compose.yaml aktualisieren**

Ersetze die bestehende `compose.yaml` durch die vollst√§ndige Version:

```yaml
services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - pg-daten:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 5s
      timeout: 5s
      retries: 5

  mongo:
    image: mongo:7
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
    volumes:
      - mongo-daten:/data/db
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "mongosh --quiet -u $$MONGO_INITDB_ROOT_USERNAME -p $$MONGO_INITDB_ROOT_PASSWORD --authenticationDatabase admin --eval \"db.adminCommand('ping').ok\" | grep 1",
        ]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 20s

  api:
    build: ./backend
    depends_on:
      postgres:
        condition: service_healthy
      mongo:
        condition: service_healthy
    environment:
      DATABASE_URL: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}"
      MONGO_URL: "mongodb://${MONGO_USER}:${MONGO_PASSWORD}@mongo:27017/?authSource=admin"

  frontend:
    build: ./frontend
    ports:
      - "3000:80"
    depends_on:
      - api

volumes:
  pg-daten:
  mongo-daten:
```

> **Was hat sich ge√§ndert gegen√ºber Teil 5?**
> - Der `api`-Service hat **keine `ports:` mehr** ‚Äî er ist nicht mehr direkt von au√üen erreichbar. Stattdessen leitet nginx (im Frontend-Container) die API-Anfragen intern weiter.
> - Der `frontend`-Service ist neu und exponiert nur **Port 3000:80**.
> - **Nur ein Port** ist von au√üen erreichbar (3000) ‚Äî das ist Best Practice! Datenbanken und Backend sind nur intern im Docker-Netzwerk sichtbar.

> **Port-Hinweis:** Falls Port 3000 belegt ist, verwende `"3001:80"` und √∂ffne `http://localhost:3001`.

> **Best Practice ‚Äî Restart-Policy:** In Produktionsumgebungen (z.B. auf EC2) solltest du `restart: unless-stopped` setzen, damit Container nach einem Server-Neustart automatisch wieder hochfahren:
> ```yaml
> api:
>   build: ./backend
>   restart: unless-stopped
>   # ...
>
> frontend:
>   build: ./frontend
>   restart: unless-stopped
>   # ...
> ```
> F√ºr lokale Entwicklung ist das optional ‚Äî Docker Desktop startet Container ohnehin nicht automatisch.

**Schritt 2: `.gitignore` erstellen**

Erstelle `.gitignore` im Projekt-Root:

```
.env
node_modules/
dist/
__pycache__/
*.pyc
```

**Schritt 3: Alles neu bauen und starten**

Stoppe zuerst alle laufenden Container und baue alles neu:

```bash
docker compose down
docker compose up -d --build
```

> **Hinweis:** Der erste Build des Frontends dauert einige Minuten, da `npm install` alle Packages herunterl√§dt. Folgende Builds sind dank Docker Layer-Caching deutlich schneller.

**Schritt 4: Status pr√ºfen**

```bash
docker compose ps
```

Du solltest 4 Services sehen:

```
NAME                    SERVICE     STATUS
rezeptbuch-postgres-1   postgres    running (healthy)
rezeptbuch-mongo-1      mongo       running (healthy)
rezeptbuch-api-1        api         running
rezeptbuch-frontend-1   frontend    running
```

Falls ein Service nicht startet, pr√ºfe die Logs:

```bash
docker compose logs api
docker compose logs frontend
```

### Die finale Architektur

```mermaid
%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#e3f2fd', 'primaryTextColor': '#0d47a1', 'primaryBorderColor': '#90caf9', 'secondaryColor': '#e8f5e9', 'secondaryTextColor': '#1b5e20', 'secondaryBorderColor': '#a5d6a7', 'tertiaryColor': '#fff3e0', 'tertiaryTextColor': '#e65100', 'tertiaryBorderColor': '#ffcc80', 'lineColor': '#78909c', 'fontSize': '14px'}}}%%
graph TD
  subgraph "compose.yaml"
    subgraph "Netzwerk (automatisch)"
      FE["üåê frontend<br/>(nginx:alpine)<br/>Port 3000:80"]
      API["üêç api<br/>(python:3.11-slim)"]
      PG["üêò postgres<br/>(postgres:16)"]
      MO["üçÉ mongo<br/>(mongo:7)"]
    end
    V1[(pg-daten)]
    V2[(mongo-daten)]
  end
  BR["üåê Browser"] -->|"Port 3000"| FE
  FE -->|"/api/ ‚Üí Proxy"| API
  API -->|"postgres:5432"| PG
  API -->|"mongo:27017"| MO
  V1 --> PG
  V2 --> MO
```

**Der Datenfluss im Detail:**

1. Browser √∂ffnet `http://localhost:3000` ‚Üí nginx liefert die React-App aus
2. React ruft `fetch("/api/rezepte")` auf ‚Üí Browser sendet an Port 3000
3. nginx erkennt `/api/` ‚Üí leitet weiter an `http://api:8000/api/rezepte`
4. FastAPI empf√§ngt die Anfrage ‚Üí fragt MongoDB nach Rezepten
5. MongoDB gibt Daten zur√ºck ‚Üí FastAPI ‚Üí nginx ‚Üí Browser

**4 Container, ein Befehl, ein Port.** Alles andere ist intern.

---

## Teil 8: Testen & Debugging

### √úbung 6: End-to-End Test

> **Ziel:** Das gesamte Setup testen ‚Äî Funktionalit√§t und Persistenz.
>
> **Zeitbedarf:** ca. 10 Minuten
>
> **Du bist fertig, wenn:** Du Kategorien und Rezepte angelegt hast, der Persistenz-Test bestanden ist, und der Health-Endpoint beide Datenbanken als "connected" meldet.

**Schritt 1: Frontend √∂ffnen**

Browser: `http://localhost:3000`

Du solltest das Rezeptbuch-Frontend sehen.

**Schritt 2: Kategorie hinzuf√ºgen**

1. Gib "Hauptgerichte" in das Kategorien-Feld ein
2. Klicke "Hinzufuegen"
3. Die Kategorie sollte in der Liste erscheinen

F√ºge noch eine hinzu: "Desserts"

**Schritt 3: Rezept hinzuf√ºgen**

1. Titel: "Spaghetti Carbonara"
2. Kategorie: "Hauptgerichte" (aus Dropdown)
3. Zutaten (eine pro Zeile):
   ```
   Spaghetti
   Eier
   Pecorino
   Guanciale
   Pfeffer
   ```
4. Schritte (einer pro Zeile):
   ```
   Wasser kochen und Pasta al dente kochen
   Eier mit geriebenem Pecorino vermischen
   Guanciale knusprig braten
   Alles vermischen und sofort servieren
   ```
5. Klicke "Rezept speichern"

Das Rezept sollte in der Liste erscheinen.

**Schritt 4: Health-Check**

Browser: `http://localhost:3000/api/health`

Sollte zeigen:

```json
{"postgres": "connected", "mongo": "connected"}
```

**Schritt 5: Persistenz-Test (der wichtigste Test!)**

```bash
# Container stoppen und l√∂schen (Volumes bleiben!)
docker compose down

# Alles wieder starten
docker compose up -d
```

Browser: `http://localhost:3000` ‚Üí **Deine Kategorien und Rezepte sind noch da!**

> Das funktioniert, weil die Named Volumes `pg-daten` und `mongo-daten` von `docker compose down` (ohne `-v`!) **nicht gel√∂scht** werden. Die Daten leben auf dem Host-Dateisystem, unabh√§ngig von den Containern. (‚Üí siehe √úbung 29.3, Teil 2: Volumes + √úbung 29.4, Teil 4: down vs. down -v)

<details>
<summary>Troubleshooting: H√§ufige Probleme und L√∂sungen</summary>

| Problem | M√∂gliche Ursache | L√∂sung |
|---------|------------------|--------|
| Frontend zeigt leere Seite | Build-Fehler im Frontend | `docker compose logs frontend` pr√ºfen |
| "Network Error" im Browser | API nicht erreichbar | `docker compose logs api` pr√ºfen |
| `/api/health` zeigt "error" | DB-Verbindung fehlgeschlagen | `docker compose ps` ‚Äî laufen die DBs? |
| Rezepte werden nicht gespeichert | MongoDB-Auth-Fehler | `.env` pr√ºfen: MONGO_USER/PASSWORD |
| Frontend zeigt "502 Bad Gateway" | API-Container nicht gestartet | `docker compose logs api` ‚Äî Fehler? |

**Debugging-Workflow:**

1. `docker compose ps` ‚Äî laufen alle 4 Container?
2. `docker compose logs <service>` ‚Äî Fehlermeldungen?
3. `docker compose config` ‚Äî compose.yaml korrekt? Variablen aufgel√∂st?
4. `docker compose exec api python -c "import psycopg2; print('OK')"` ‚Äî Packages installiert?

</details>

---

## Teil 9: Ausblick ‚Äî Deployment auf EC2

Dein Projekt l√§uft lokal. Wie bekommst du es auf einen Server? Hier ein kurzer √úberblick. Die Details findest du in √úbung 26.4 (AWS-Deployment).

### Was brauchst du auf EC2?

| Schritt | Befehl / Aktion |
|---------|-----------------|
| 1. Docker installieren | `sudo dnf install docker` + `sudo systemctl start docker` + `sudo systemctl enable docker` |
| 2. Docker Compose installieren | `sudo dnf install docker-compose-plugin` |
| 3. Projektdateien hochladen | `git clone ...` oder `scp -r` |
| 4. `.env`-Datei erstellen | Manuell auf dem Server (nicht aus Git!) |
| 5. Starten | `docker compose up -d --build` |
| 6. Security Group | Port 80 √∂ffnen (‚Üí siehe √úbung 26.4, Teil 3.1) |

> **Docker ohne `sudo`:** Standardm√§√üig braucht jeder Docker-Befehl `sudo`. Um das zu vermeiden, f√ºge deinen User zur `docker`-Gruppe hinzu:
> ```bash
> sudo usermod -aG docker $USER
> ```
> Danach **neu einloggen** (SSH-Session schlie√üen und neu verbinden), damit die Gruppen√§nderung wirkt. Ab dann funktioniert `docker compose up -d` ohne `sudo`.

### Was √§ndert sich gegen√ºber lokal?

| Aspekt | Lokal | EC2 |
|--------|-------|-----|
| Frontend-Port | `3000:80` | `80:80` (Standard-HTTP-Port) |
| Port-Binding | `"127.0.0.1:3000:80"` (optional) | `"80:80"` (Security Group regelt Zugriff) |
| `.env`-Datei | Im Projektordner | Manuell auf dem Server erstellen |
| Images | Werden lokal gebaut | Werden auf dem Server gebaut |
| Zugriff | `http://localhost:3000` | `http://DEINE-PUBLIC-IP` |

> **Tipp:** √Ñndere in der compose.yaml nur den Frontend-Port auf `"80:80"` ‚Äî alles andere bleibt gleich. Das ist die St√§rke von Docker: Was lokal l√§uft, l√§uft (fast) identisch auf dem Server.

> **F√ºr die vollst√§ndige EC2-Anleitung** (Instanz erstellen, SSH-Zugang, Security Groups, Server einrichten): ‚Üí siehe **√úbung 26.4: React-App auf AWS deployen**, Teil 3.

---

### Wissensfrage 9

**Welche zwei Dinge musst du auf einem EC2-Server zus√§tzlich installieren, die auf deinem Laptop durch Docker Desktop bereits vorhanden sind?**

<details>
<summary>Antwort anzeigen</summary>

1. **Docker Engine** ‚Äî die Container-Runtime. Auf EC2 installierst du die Engine direkt (z.B. `sudo dnf install docker` auf Amazon Linux 2023), da es kein Docker Desktop gibt.

2. **Docker Compose Plugin** ‚Äî das Compose-CLI. `sudo dnf install docker-compose-plugin` installiert den `docker compose`-Befehl.

Auf deinem Laptop √ºbernimmt **Docker Desktop** beides: Es installiert die Docker Engine und das Compose Plugin zusammen mit einer grafischen Oberfl√§che. Auf einem Server brauchst du die GUI nicht ‚Äî nur die CLI-Tools.

</details>

---

## Bonus: Best Practices Review

### √úbung 7: "Schlechte" compose.yaml verbessern

> **Ziel:** Eine absichtlich schlecht geschriebene compose.yaml erkennen und nach Best Practices √ºberarbeiten.
>
> **Zeitbedarf:** ca. 15 Minuten
>
> **Du bist fertig, wenn:** Du alle Probleme gefunden und eine verbesserte Version erstellt hast.

**Die "schlechte" compose.yaml (8 Probleme finden):**

```yaml
version: "3"

services:
  db:
    image: postgres
    environment:
      POSTGRES_PASSWORD: supergeheim123
    ports:
      - "5432:5432"

  mongo:
    image: mongo:latest
    ports:
      - "27017:27017"

  api:
    build: .
    ports:
      - "8000:8000"
    depends_on:
      - db

  frontend:
    build: ./frontend
    ports:
      - "3000:80"
    depends_on:
      - api
```

**Finde die 8 Probleme!** √úberlege, was du in den letzten 5 Tagen √ºber Docker-Best-Practices gelernt hast.

<details>
<summary>Hinweise (falls du nicht weiterkommst)</summary>

1. Schau dir die erste Zeile an ‚Äî wird die noch gebraucht?
2. Welches Image-Tag verwendet `postgres`?
3. Wo sind die Passw√∂rter?
4. M√ºssen alle Ports nach au√üen exponiert werden?
5. Gibt es Healthchecks?
6. Wie wartet `api` auf die Datenbank?
7. Wo werden die Daten gespeichert?
8. Welches Image-Tag verwendet `mongo`?

</details>

<details>
<summary>L√∂sung: Alle 8 Probleme</summary>

| # | Problem | Best Practice |
|---|---------|---------------|
| 1 | `version: "3"` | Nicht mehr n√∂tig ‚Äî Compose Specification erkennt das Format automatisch. Weglassen. |
| 2 | `image: postgres` (ohne Tag) | Immer **explizite Tags** verwenden: `postgres:16`. Sonst wird `:latest` gezogen ‚Üí unvorhersehbare Versionen. |
| 3 | `image: mongo:latest` | `:latest` ist **nicht** "die neueste stabile Version" ‚Äî es ist einfach ein Tag-Name, der sich jederzeit √§ndern kann. Besser: `mongo:7`. |
| 4 | `POSTGRES_PASSWORD: supergeheim123` | Passw√∂rter **nie** direkt in die compose.yaml! In `.env`-Datei auslagern + `${POSTGRES_PASSWORD}`. |
| 5 | `ports: "5432:5432"` bei DB | Datenbank-Ports **nicht exponieren** wenn nur die API darauf zugreift. Nur der Frontend-Port muss nach au√üen. |
| 6 | `ports: "27017:27017"` bei Mongo | Gleich wie bei PostgreSQL ‚Äî MongoDB braucht keinen externen Port. |
| 7 | Kein `depends_on: condition: service_healthy` | Einfaches `depends_on` wartet nicht auf DB-Bereitschaft. Healthchecks erg√§nzen! |
| 8 | Keine `volumes:` f√ºr Datenbanken | Ohne Named Volumes gehen **alle Daten verloren** bei `docker compose down`! |

**Verbesserte Version:**

```yaml
services:
  db:
    image: postgres:16
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - pg-daten:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 5s
      timeout: 5s
      retries: 5

  mongo:
    image: mongo:7
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
    volumes:
      - mongo-daten:/data/db
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "mongosh --quiet -u $$MONGO_INITDB_ROOT_USERNAME -p $$MONGO_INITDB_ROOT_PASSWORD --authenticationDatabase admin --eval \"db.adminCommand('ping').ok\" | grep 1",
        ]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 20s

  api:
    build: ./backend
    depends_on:
      db:
        condition: service_healthy
      mongo:
        condition: service_healthy
    environment:
      DATABASE_URL: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}"

  frontend:
    build: ./frontend
    ports:
      - "3000:80"
    depends_on:
      - api

volumes:
  pg-daten:
  mongo-daten:
```

</details>

---

## Aufr√§umen

Wenn du mit allen √úbungen fertig bist:

**√úbung 1 (Multi-Stage):** Wurde bereits in √úbung 1 aufger√§umt.

**√úbungen 2‚Äì7 (Rezeptbuch-Projekt):**

```bash
docker compose down --rmi local -v --remove-orphans
```

> **Was machen die Flags?**
> - `--rmi local` ‚Üí l√∂scht die lokal gebauten Images (api, frontend), nicht die von Docker Hub gezogenen (postgres, mongo)
> - `-v` ‚Üí l√∂scht die Named Volumes (pg-daten, mongo-daten) ‚Üí **Daten werden gel√∂scht!**
> - `--remove-orphans` ‚Üí entfernt Container von Services, die nicht mehr in der compose.yaml stehen (z.B. nach Umbenennung)
>
> Nur verwenden, wenn du das Projekt wirklich aufr√§umen willst.

<details>
<summary>Git Bash / macOS / Linux</summary>

```bash
cd ..
rm -rf rezeptbuch
```

</details>

<details>
<summary>PowerShell</summary>

```powershell
cd ..
Remove-Item -Recurse -Force rezeptbuch
```

</details>

<details>
<summary>CMD</summary>

```cmd
cd ..
rmdir /s /q rezeptbuch
```

</details>

---

## Abschluss-Checkliste

√úberpr√ºfe, ob du die Lernziele erreicht hast:

- [ ] Ich kann einen **Multi-Stage Build** erstellen und den Gr√∂√üenvorteil erkl√§ren
- [ ] Ich kann die **Projektstruktur** f√ºr eine Multi-Container-App organisieren (compose.yaml im Root, Dockerfile pro Service)
- [ ] Ich kenne den empfohlenen **Development-Workflow** mit Docker (DBs sofort, Code containerisieren am Ende)
- [ ] Ich kann **PostgreSQL + MongoDB** gemeinsam in Compose konfigurieren (Healthchecks, Volumes, Authentifizierung)
- [ ] Ich kann ein **FastAPI-Backend** mit zwei Datenbanken verbinden (psycopg2 + motor)
- [ ] Ich kann eine **React-App** per Multi-Stage Build in ein nginx-Image verpacken (node ‚Üí nginx)
- [ ] Ich kann einen **nginx Reverse-Proxy** konfigurieren (SPA-Routing + API-Weiterleitung)
- [ ] Ich kann ein **4-Container-Setup** mit Compose orchestrieren (Frontend + API + PostgreSQL + MongoDB)
- [ ] Ich setze **.env / .env.example / .gitignore** korrekt ein und wei√ü, warum Secrets nicht in die compose.yaml geh√∂ren
- [ ] Ich kann die App **end-to-end testen** (Funktionalit√§t, Persistenz, Health-Endpoint)
- [ ] Ich wei√ü, was sich beim **EC2-Deployment** gegen√ºber lokal √§ndert (Docker installieren, Port 80, Security Group)
- [ ] Ich kann **Docker Best Practices** anwenden (explizite Tags, Healthchecks, keine Secrets in YAML, nur n√∂tige Ports)

> **Gl√ºckwunsch!** Du hast in 5 Tagen den kompletten Weg von "Was ist ein Container?" bis zu einem professionellen Multi-Container-Projekt mit Docker Compose gemeistert. Diese F√§higkeiten sind in der modernen Webentwicklung Standard ‚Äî ob im Team, in CI/CD-Pipelines oder beim Cloud-Deployment.
